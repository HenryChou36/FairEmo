{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "import fairseq\n",
    "import librosa\n",
    "import torch\n",
    "import speechbrain as sb\n",
    "import torch\n",
    "import os\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from tqdm import tqdm\n",
    "import hdbscan\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_distances, pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialized Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/mnt/sda/hsinghang/dataset/MSP-Podcast-v1.10/labels/labels_consensus.csv')\n",
    "df = pd.DataFrame(columns=['file_name', 'emotion', 'A', 'V', 'D', 'spk_id', 'gender', 'split', 'wav_path', 'hubert_path', 'hubert_len', 'emb_xvec', 'hdb_label'])\n",
    "df['file_name'] = labels['FileName']\n",
    "df['emotion'] = labels['EmoClass']\n",
    "df['A'] = labels['EmoAct']\n",
    "df['V'] = labels['EmoVal']\n",
    "df['D'] = labels['EmoDom']\n",
    "df['spk_id'] = labels['SpkrID']\n",
    "df['gender'] = labels['Gender']\n",
    "df['split'] = labels['Split_Set']\n",
    "\n",
    "# modify this to make it point to where your wav files are stored\n",
    "df['wav_path'] = '/mnt/sda/hsinghang/dataset/MSP-Podcast-v1.10/audios/' + df['file_name']\n",
    "# modify following to make them points to where you want to store these features\n",
    "df['hubert_path'] = '/mnt/sda/hsinghang/dataset/MSP-Podcast-v1.10/features/hubert/' + df['file_name'].str.replace('.wav', '.pkl')\n",
    "df['emb_xvec'] = '/mnt/sda/hsinghang/dataset/MSP-Podcast-v1.10/features/emb/xvec/' + df['file_name'].str.replace('.wav', '.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Hubert Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# check point path\n",
    "ckpt_path = '/homes/hsinghang/model/hubert/hubert_base_ls960.pt'\n",
    "models, _, _ = fairseq.checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
    "model = models[0]\n",
    "model.to(device)\n",
    "\n",
    "wav_list = list(df['wav_path'])\n",
    "out_list = list(df['hubert_path'])\n",
    "seq_len = [0] * len(out_list)\n",
    "for c, wav_path in enumerate(tqdm(wav_list)):\n",
    "    #s, sr = sf.read(wav_path)\n",
    "    #print(sr)\n",
    "    s, sr = librosa.load(wav_path, sr=16000)\n",
    "    assert s.ndim == 1, s.ndim\n",
    "    feats_audio = torch.FloatTensor(s).reshape((1, -1))\n",
    "    with torch.no_grad():\n",
    "        feats_audio = feats_audio.to(device)\n",
    "        z = model.extract_features(feats_audio)[0]\n",
    "        z = z.cpu().detach().numpy().squeeze()\n",
    "    seq_len[c] = len(z)\n",
    "    out_path = '/'.join(out_list[c].split('/')[:-1])\n",
    "    path = Path(out_path)\n",
    "    if not os.path.exists(str(path.as_posix())):\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    joblib.dump(z, out_list[c])\n",
    "    if c % 1000 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "#iemocap_meta['hubert_feature'] = out_list\n",
    "df['hubert_len'] = seq_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Speaker Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "run_opts={\"device\":\"cuda\"} \n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    wav_path = row['wav_path']\n",
    "    emb_path = row['emb_xvec']\n",
    "    signal, fs = torchaudio.load(wav_path)\n",
    "    #signal = signal.to(device)\n",
    "    embs = classifier.encode_batch(signal)\n",
    "    joblib.dump(embs.cpu().numpy().squeeze(), emb_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['split'] == 'Train']\n",
    "valid_df = df[df['split'] == 'Development']\n",
    "test_df = df[(df['split'] == 'Test1') | (df['split'] == 'Test2')]\n",
    "# I think we actually only use test 1 to evaluate fairness since Test 2 are speakers with unknown id and is filtered out by data_loader.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cluster label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get speaker embedding for each set\n",
    "MIN_SAMPLE = 32\n",
    "train_emb = []\n",
    "for emb in tqdm(train_df['emb_xvec']):\n",
    "    train_emb.append(joblib.load(emb))\n",
    "train_emb = np.array(train_emb)\n",
    "\n",
    "valid_emb = []\n",
    "for emb in tqdm(valid_df['emb_xvec']):\n",
    "    valid_emb.append(joblib.load(emb))\n",
    "valid_emb = np.array(valid_emb)\n",
    "\n",
    "test_emb = []\n",
    "for emb in tqdm(test_df['emb_xvec']):\n",
    "    test_emb.append(joblib.load(emb))\n",
    "test_emb = np.array(test_emb)\n",
    "\n",
    "train_v, train_c = np.unique(train_df['spk_id'], return_counts=True)\n",
    "train_v = train_v[train_c >= MIN_SAMPLE]\n",
    "train_v = train_v[train_v != 'Unknown']\n",
    "selected_train_emb = train_emb[np.isin(train_df['spk_id'].to_numpy(), train_v)]\n",
    "\n",
    "valid_v, c = np.unique(valid_df['spk_id'], return_counts=True)\n",
    "valid_v = valid_v[c >= MIN_SAMPLE]\n",
    "valid_v = valid_v[valid_v != 'Unknown']\n",
    "selected_valid_emb = valid_emb[np.isin(valid_df['spk_id'].to_numpy(), valid_v)]\n",
    "\n",
    "test_v, c = np.unique(test_df['spk_id'], return_counts=True)\n",
    "test_v = test_v[c >= MIN_SAMPLE]\n",
    "test_v = test_v[test_v != 'Unknown']\n",
    "selected_test_emb = test_emb[np.isin(test_df['spk_id'].to_numpy(), test_v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA for dimension reduction\n",
    "pca = PCA(n_components=.80)\n",
    "pca.fit(selected_train_emb)\n",
    "selected_pca_train_emb = pca.transform(selected_train_emb)\n",
    "selected_pca_valid_emb = pca.transform(selected_valid_emb)\n",
    "selected_pca_test_emb = pca.transform(selected_test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clusterer = hdbscan.HDBSCAN(min_cluster_size=32, min_samples=4)\n",
    "train_clusterer.fit(selected_pca_train_emb)\n",
    "\n",
    "valid_clusterer = hdbscan.HDBSCAN(min_cluster_size=32, min_samples=4)\n",
    "valid_clusterer.fit(selected_pca_valid_emb)\n",
    "\n",
    "test_clusterer = hdbscan.HDBSCAN(min_cluster_size=32, min_samples=4)\n",
    "test_clusterer.fit(selected_pca_test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit noise node\n",
    "train_cluster_avg_emb = []\n",
    "for i in range(train_clusterer.labels_.max()):\n",
    "    train_cluster_avg_emb.append(np.mean(selected_pca_train_emb[train_clusterer.labels_ == i], axis=0, keepdims=False))\n",
    "train_cluster_avg_emb = np.array(train_cluster_avg_emb)\n",
    "\n",
    "valid_cluster_avg_emb = []\n",
    "for i in range(valid_clusterer.labels_.max()):\n",
    "    valid_cluster_avg_emb.append(np.mean(selected_pca_valid_emb[valid_clusterer.labels_ == i], axis=0, keepdims=False))\n",
    "valid_cluster_avg_emb = np.array(valid_cluster_avg_emb)\n",
    "\n",
    "test_cluster_avg_emb = []\n",
    "for i in range(test_clusterer.labels_.max()):\n",
    "    test_cluster_avg_emb.append(np.mean(selected_pca_test_emb[test_clusterer.labels_ == i], axis=0, keepdims=False))\n",
    "test_cluster_avg_emb = np.array(test_cluster_avg_emb)\n",
    "\n",
    "train_noise_similarity = cosine_similarity(selected_pca_train_emb[train_clusterer.labels_==-1], train_cluster_avg_emb)\n",
    "valid_noise_similarity = cosine_similarity(selected_pca_valid_emb[valid_clusterer.labels_==-1], valid_cluster_avg_emb)\n",
    "test_noise_similarity = cosine_similarity(selected_pca_test_emb[test_clusterer.labels_==-1], test_cluster_avg_emb)\n",
    "\n",
    "train_noise_fitted_label = np.copy(train_clusterer.labels_)\n",
    "j = 0\n",
    "for i, clust_lab in enumerate(train_clusterer.labels_):\n",
    "    if clust_lab == -1:\n",
    "        train_noise_fitted_label[i] = np.argmax(train_noise_similarity[j])\n",
    "        j += 1\n",
    "\n",
    "valid_noise_fitted_label = np.copy(valid_clusterer.labels_)\n",
    "j = 0\n",
    "for i, clust_lab in enumerate(valid_clusterer.labels_):\n",
    "    if clust_lab == -1:\n",
    "        valid_noise_fitted_label[i] = np.argmax(valid_noise_similarity[j])\n",
    "        j += 1\n",
    "test_noise_fitted_label = np.copy(test_clusterer.labels_)\n",
    "j = 0\n",
    "for i, clust_lab in enumerate(test_clusterer.labels_):\n",
    "    if clust_lab == -1:\n",
    "        test_noise_fitted_label[i] = np.argmax(test_noise_similarity[j])\n",
    "        j +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make labels out of expieriment to -2\n",
    "hdb_labels = np.ones(len(train_df['file_name'])) * -2\n",
    "hdb_labels[np.isin(train_df['spk_id'].to_numpy(), train_v)] = train_noise_fitted_label\n",
    "train_df['hdb_label'] = hdb_labels.astype('int')\n",
    "\n",
    "hdb_labels = np.ones(len(valid_df['file_name'])) * -2\n",
    "hdb_labels[np.isin(valid_df['spk_id'].to_numpy(), valid_v)] = valid_noise_fitted_label\n",
    "valid_df['hdb_label'] = hdb_labels.astype('int')\n",
    "\n",
    "hdb_labels = np.ones(len(test_df['file_name'])) * -2\n",
    "hdb_labels[np.isin(test_df['spk_id'].to_numpy(), test_v)] = test_noise_fitted_label\n",
    "test_df['hdb_label'] = hdb_labels.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save result meta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./feature_extract/MSP/train_meta_hdb.csv', index=True)\n",
    "valid_df.to_csv('./feature_extract/MSP/valid_meta_hdb.csv', index=True)\n",
    "test_df.to_csv('./feature_extract/MSP/test_meta_hdb.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_fairness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
